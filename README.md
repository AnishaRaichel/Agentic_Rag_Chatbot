# Agentic_Rag_Chatbot

A modular Agentic Retrieval-Augmented Generation (RAG) system built using CrewAI, FastAPI, Streamlit, Groq, LlamaIndex, and ChromaDB.

AstraRAG enables grounded, document-aware conversational AI with structured outputs and transparent reasoning.

---

## ğŸ§  Tech Stack

- **CrewAI** â€“ Agent orchestration  
- **FastAPI** â€“ Backend API  
- **Streamlit** â€“ Frontend UI  
- **Groq (LLaMA 3.3 70B)** â€“ LLM inference  
- **LlamaIndex** â€“ RAG pipeline  
- **ChromaDB** â€“ Vector database  
- **HuggingFace Embeddings** â€“ Text embeddings  
- **Docker** â€“ Containerization  

---

## ğŸ—ï¸ Architecture Flow

1. User sends query via Streamlit UI  
2. FastAPI receives chat history  
3. CrewAI agent executes RAG task  
4. Retrieval tool queries ChromaDB  
5. Groq LLM generates grounded response  
6. Structured JSON response returned:
   - `answer`
   - `sources`
   - `tool_used`
   - `rationale`

---

## ğŸ“‚ Project Structure

```
Agentic_Rag_Chatbot/
â”‚
â”œâ”€â”€ agents_src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ tools/
â”‚   â””â”€â”€ llm/
â”‚
â”œâ”€â”€ backend_src/
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ services/
â”‚
â”œâ”€â”€ frontend_src/
â”œâ”€â”€ rag_doc_ingestion/
â”œâ”€â”€ doc_vector_store/
â”œâ”€â”€ docs_dir/
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ start.sh
```
